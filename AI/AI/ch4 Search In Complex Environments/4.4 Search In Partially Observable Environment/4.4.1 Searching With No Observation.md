When the agent's percepts provide no information, we have what is called **sensorless** problem (or **conformant** problem). 
Consider sensorless version of vacuum cleaner world. Assume that the agent does not know geography of the world, no its location, no dirt distribution. In that case, its initial [[Belief State]] is all states {1, 2, 3, 4, ,5, 6, 7, 8}. Now, if agent moves right, it reduces its [[Belief State]] to {2, 4, 6, 8} - the agent gained information without receiving perceipts. After _suck_ command the states are {4, 8}. Finally, after more _left_, _suck_ the agent is guaranteed to reach the goal state no matted what initial position is. The agent **coerce** the environment into the goal state.
We can reduce sensorless search problem into search problem:
__States__: the belief-state space contains every possible subset of physical states. If P has N states, then belief-state problem has 2^N belief states.
__Initial state__: The belief state is a set of all physical states.
__Actions__: Suppose the agent is in belief state b = {s1, s2}, but Actions(s1) != Actions(s2), then agent is not sure which action is legal. Generally 
$$
Actions(b) = U Actions(S) where sEb
$$

__Transition Model__:
$$
b' = Result(b, a) = U Results(s, a) where  s E b
$$
__Goal__:
__Action cost__: 
